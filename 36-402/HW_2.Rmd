---
title: "36-402 Homework 2"
author: "James \"Morgan\" Hawkins"
date: "Friday Feb 3, 2023"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

We recommend using R Markdown for all homework aassignments. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a PDF will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars, fig.width = 10, fig.height = 4}
cars.train <- read.csv("/Users/morganhawkins/Downloads/cars_train.csv")
cars.test <- read.csv("/Users/morganhawkins/Downloads/cars_test.csv")

#par(mfrow = c(1,2))
#plot(cars.train$Miles, cars.train$Price, pch = ".")
#plot(cars.train$Year, cars.train$Price, pch = ".")

#summary(cars.train)
#summary(cars.test)

```

## Problem 1


### Problem 1 (a)


```{r}
cor(cars.train)
```


Year is positively correlated with price with a correlation coefficient of .492 while Miles is negatively correlated with price with a correlation coefficient of -.474. Year and miles are negatively correlated with each other with a correlation coefficient of -.483


### Problem 1 (b)


```{r}
model.0 <- lm(Price ~ 1, data = cars.train)
model.1 <- lm(Price ~ Miles, data = cars.train)
model.2 <- lm(Price ~ Year, data = cars.train)
model.3 <- lm(Price ~ Year + Miles, data = cars.train)
model.4 <- lm(Price ~ factor(Year) + Miles, data = cars.train)

#summary(model.0)
#summary(model.1)
#summary(model.2)
#summary(model.3)
#summary(model.4)
```


```{r, fig.height = 4, fig.width = 10}
# model.0 residual plots
par(mfrow = c(1,2))
hist(residuals(model.0), main = "Null Model Residuals Distribution", xlab = "Residual")
plot(model.0,2, pch = ".")
```


We can see on the histrogram above that our residuals appear to have a right skewed distribution. The QQ plot also appears to be very non linear indicating that our residuals also are not normally distributed. 


```{r, fig.height = 10, fig.width = 11}
# model.1 residuals plots
par(mfrow = c(3,2))
plot(cars.train$Miles, residuals(model.1), main = "Model.1 Residual vs Miles", pch = ".", ylab = "Residual", xlab = "Miles")
abline(lm(residuals(model.1) ~ cars.train$Miles), col = "red")
plot(model.1, pch = ".")

```


On the plots above we see on the Residual vs Predictor plot that the residuals are liekly not independently and identically distributed with mean 0. The variance of the residuals does not appear constant and decreases with increases in the variable price. On the QQ plot, we see that our residuals are liekly not normally distributed as shown by how far the plot strays from the theoretical line. 


```{r, fig.height = 10, fig.width = 11}
# model.2 residuals plots
par(mfrow = c(3,2))
#plot(cars.train$Year, residuals(model.2), main = "Model.2 Residual vs Year", pch = ".", ylab = "Residual", xlab = "Year")
boxplot(Price ~ Year, data= cars.train)
abline(lm(residuals(model.2) ~ cars.train$Year), col = "red")
plot(model.1, pch = ".")

```


Our residuals for the fit of model.2 have similar issues to model.1. The variance of our residuals appears to have a relationship with the predictor Year so our assumption of residuals with mean 0 and constant variance is violated and the residuals are likely not normally distributed as shown by the QQ plot. 


```{r, fig.height = 10, fig.width = 11}
# model.3 residuals plots
par(mfrow = c(3,2))

plot(cars.train$Year, residuals(model.3), main = "Model.3 Residual vs Year", pch = ".", ylab = "Residual", xlab = "Year")
abline(lm(residuals(model.3) ~ cars.train$Year), col = "red")

plot(cars.train$Miles, residuals(model.3), main = "Model.3 Residual vs Miles", pch = ".", ylab = "Residual", xlab = "Miles")
abline(lm(residuals(model.3) ~ cars.train$Miles), col = "red")

plot(model.3, pch = ".")

```


Model 3 does resolve the issue of correlation between the predictors leading to the overestimation of relationships, but it doesn't appear that including both predictors resolved our issues in model 1 and 2. On the residuals vs. fitted plot there appears to be a negative relationship between the fitted value and the residual indicating that our residuals are likely nor identically distributed. On the same plot we can also see that larger fitted values are associated with higher variance in the residuals. This violates our assumption of constant variance of our residuals. On the QQ plot we see the plot stray far away from the theoretical line indicating that our residuals are not normally distributed. 


```{r, fig.height = 10, fig.width = 10}
# model.4 residuals plots
par(mfrow = c(3,2))

plot(cars.train$Year, residuals(model.4), main = "Model.4 Residual vs Year", pch = ".", ylab = "Residual", xlab = "Year")
abline(lm(residuals(model.4) ~ cars.train$Year), col = "red")

plot(cars.train$Miles, residuals(model.4), main = "Model.4 Residual vs Miles", pch = ".", ylab = "Residual", xlab = "Miles")
abline(lm(residuals(model.4) ~ cars.train$Miles), col = "red")

plot(model.4, pch = ".")

```


Model 4 also does not address any of the issues encountered with our fit in model 1 and 2. The residuals don't appear to have constant mean 0 and constant variance as seen on the residual vs. fitted plot. Also, our residuals still don't appear to be normally distributed as shown by the how far our plot strays away from the theoretical line.


### Problem 1 (c)


The corresponding coefficients are different in model 3 than in model 1 and model 2 because the predictors Miles and Year are not independent of eachother. So, in the univariate models, effects from other correlated predictors are captured in the estimate of the relationship between the response and the single predictor.


### Problem 1 (d)


```{r}

temp.dat <- cars.train
for(i in 1:10){
  temp.dat[,paste("simul",i,sep = ".")] = rnorm(nrow(cars.train), mean = 1000, sd = 1500)
}

model.5 <- lm(Price ~ Miles + Year + simul.1 + simul.2 + simul.3 + simul.4 + 
              simul.5 + simul.6 + simul.7 + simul.8 + simul.9 + simul.10, 
              data = temp.dat)

#summary(model.5)

```


The covariates were simulated by sampling from a normal distribution. Each sample had mean 1000 and standard deviation of 1500. Our samples were all iid. 


### Problem 1 (e)


```{r}
train.errors = c(0,0,0,0,0,0)

train.errors[1] = mean(residuals(model.0)^2)
train.errors[2] = mean(residuals(model.1)^2)
train.errors[3] = mean(residuals(model.2)^2)
train.errors[4] = mean(residuals(model.3)^2)
train.errors[5] = mean(residuals(model.4)^2)
train.errors[6] = mean(residuals(model.5)^2)

error.df <- data.frame(
  model = c("model.0","model.1","model.2","model.3","model.4","model.5"),
  train.error = train.errors
  
)

error.df[order(error.df$train.error, decreasing = F),]


```

Model 5 ranks slightly better than model 3. We expect this training error to go to 0 as the number of uncorrelated covariates approaches the number of samples in our data. 


### Problem 1 (f)


```{r}
temp.test.dat <- cars.test
for(i in 1:10){
  temp.test.dat[,paste("simul",i,sep = ".")] = rnorm(nrow(cars.test), mean = 0, sd = 10)
}


test.errors = c(0,0,0,0,0,0)

test.errors[1] = mean( (predict(model.0, cars.test) - cars.test$Price)^2 )
test.errors[2] = mean( (predict(model.1, cars.test) - cars.test$Price)^2 )
test.errors[3] = mean( (predict(model.2, cars.test) - cars.test$Price)^2 )
test.errors[4] = mean( (predict(model.3, cars.test) - cars.test$Price)^2 )
test.errors[5] = mean( (predict(model.4, cars.test) - cars.test$Price)^2 )
test.errors[6] = mean( (predict(model.5, temp.test.dat) - temp.test.dat$Price)^2 )

error.df$test.error = test.errors

error.df[order(error.df$test.error, decreasing = F),]

```


Based on the diagnostics performed above, I believe model 4 is the best choice. Model 4 has the best train and test error, so it explains the most variance in the response variable while not overfitting (sads shown by having a better test error)





























